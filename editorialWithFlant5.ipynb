{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzs2DHvcxhiXNelhaufTJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamideshahrabi/editorial_assistant/blob/main/editorialWithFlant5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-iHh1IyCQ0B",
        "outputId": "88d114f3-14d8-412b-a46f-7f9b553ba9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Installing dependencies...\n",
            "\n",
            "Downloading models...\n",
            "SentenceTransformer model downloaded\n",
            "Flan-T5 model and tokenizer downloaded\n",
            "\n",
            "Writing articles.json...\n",
            "\n",
            "Verifying articles.json content...\n",
            "Content length: 1982 characters\n",
            "First 100 characters: [\n",
            "  {\n",
            "    \"content_id\": \"article1\",\n",
            "    \"content_headline\": \"CBC N.L. launches campaign to support f\n",
            "Last 100 characters:  content and the importance of protecting sources who share information through social media.\"\n",
            "  }\n",
            "]\n",
            "JSON is valid\n",
            "\n",
            "Writing policies.txt...\n",
            "main.py has been updated successfully!\n",
            "\n",
            "Created project structure in Google Drive:\n",
            "Project directory: /content/drive/MyDrive/editorial_assistant\n",
            "\n",
            "Verifying directory structure:\n",
            "Directory contents: ['data', 'src', 'test_server.py', 'editorial_assistant', 'server.log', 'run_server.py', 'requirements.txt']\n",
            "src directory contents: ['api', '__pycache__', '__init__.py']\n",
            "src/api directory contents: ['__pycache__', '__init__.py', 'main.py']\n",
            "data directory contents: ['.DS_Store', 'policies.txt', 'articles.json']\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Mount Google Drive and set up project\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory in Google Drive\n",
        "project_dir = '/content/drive/MyDrive/editorial_assistant'\n",
        "os.makedirs(f'{project_dir}/data', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/src/api', exist_ok=True)\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\nInstalling dependencies...\")\n",
        "!pip install -q sentence-transformers transformers torch faiss-cpu fastapi uvicorn huggingface_hub[hf_xet]\n",
        "\n",
        "# Download models\n",
        "print(\"\\nDownloading models...\")\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Download SentenceTransformer model\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"SentenceTransformer model downloaded\")\n",
        "\n",
        "# Download Flan-T5 model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "print(\"Flan-T5 model and tokenizer downloaded\")\n",
        "\n",
        "# Create requirements.txt\n",
        "requirements = \"\"\"fastapi>=0.104.1\n",
        "uvicorn>=0.24.0\n",
        "sentence-transformers>=2.2.2\n",
        "faiss-cpu>=1.7.4\n",
        "transformers>=4.35.2\n",
        "torch>=2.1.1\n",
        "numpy>=1.26.0\n",
        "pydantic>=2.7.4\n",
        "requests>=2.31.0\n",
        "python-multipart>=0.0.6\"\"\"\n",
        "\n",
        "with open(f'{project_dir}/requirements.txt', 'w') as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "# Create articles.json\n",
        "articles = [\n",
        "    {\n",
        "        \"content_id\": \"article1\",\n",
        "        \"content_headline\": \"CBC N.L. launches campaign to support food banks\",\n",
        "        \"content_type\": \"news\",\n",
        "        \"content_publish_time\": \"2024-01-15T10:00:00Z\",\n",
        "        \"content_last_update\": \"2024-01-15T10:00:00Z\",\n",
        "        \"content_categories\": [\"Community\", \"Food Security\"],\n",
        "        \"content_tags\": [\"food bank\", \"community support\", \"CBC N.L.\"],\n",
        "        \"content_word_count\": 450,\n",
        "        \"content_department_path\": \"/news/local\",\n",
        "        \"body\": \"CBC N.L. has launched a campaign to support food banks across the province. The initiative, in partnership with the Community Food Sharing Association, aims to raise awareness and collect donations for food banks that are seeing increased demand. With rising food costs and economic challenges, many families are turning to food banks for support. The campaign will run for the next month, with special programming and community events planned throughout the province.\"\n",
        "    },\n",
        "    {\n",
        "        \"content_id\": \"article2\",\n",
        "        \"content_headline\": \"New guidelines for social media reporting\",\n",
        "        \"content_type\": \"policy\",\n",
        "        \"content_publish_time\": \"2024-01-10T14:30:00Z\",\n",
        "        \"content_last_update\": \"2024-01-10T14:30:00Z\",\n",
        "        \"content_categories\": [\"Policy\", \"Social Media\"],\n",
        "        \"content_tags\": [\"social media\", \"reporting guidelines\", \"journalism\"],\n",
        "        \"content_word_count\": 600,\n",
        "        \"content_department_path\": \"/news/policy\",\n",
        "        \"body\": \"CBC has released updated guidelines for social media reporting. The new policy emphasizes accuracy, transparency, and responsible use of social media platforms. Journalists are required to verify information from social media sources before reporting, maintain professional boundaries, and clearly distinguish between personal and professional accounts. The guidelines also address the use of user-generated content and the importance of protecting sources who share information through social media.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "articles_path = f'{project_dir}/data/articles.json'\n",
        "print(\"\\nWriting articles.json...\")\n",
        "with open(articles_path, 'w') as f:\n",
        "    json.dump(articles, f, indent=2)\n",
        "\n",
        "# Verify articles.json content\n",
        "print(\"\\nVerifying articles.json content...\")\n",
        "with open(articles_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(f\"Content length: {len(content)} characters\")\n",
        "    print(f\"First 100 characters: {content[:100]}\")\n",
        "    print(f\"Last 100 characters: {content[-100:]}\")\n",
        "    # Verify JSON is valid\n",
        "    try:\n",
        "        json.loads(content)\n",
        "        print(\"JSON is valid\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Invalid JSON - {str(e)}\")\n",
        "\n",
        "# Create policies.txt\n",
        "policies = '''CBC Editorial Guidelines: Anonymous Sources\n",
        "\n",
        "Anonymous sources should only be used when:\n",
        "1. The information is of significant public interest\n",
        "2. The source would face serious consequences if identified\n",
        "3. The information cannot be obtained through on-the-record sources\n",
        "\n",
        "When using anonymous sources:\n",
        "- Verify the information through multiple sources\n",
        "- Clearly explain to readers why anonymity was granted\n",
        "- Use descriptive terms (e.g., \"senior government official\" instead of just \"source\")\n",
        "- Document the source's credentials and relationship to the story\n",
        "\n",
        "CBC Editorial Guidelines: Headlines\n",
        "\n",
        "Headlines should:\n",
        "1. Be accurate and reflect the content\n",
        "2. Avoid sensationalism\n",
        "3. Use clear, concise language\n",
        "4. Include relevant keywords for SEO\n",
        "5. Follow CBC's style guide for capitalization and punctuation\n",
        "\n",
        "CBC Editorial Guidelines: Social Media\n",
        "\n",
        "When creating content for social media:\n",
        "1. Keep summaries concise and engaging\n",
        "2. Use appropriate hashtags\n",
        "3. Include key information in the first 280 characters\n",
        "4. Maintain CBC's voice and tone\n",
        "5. Ensure accuracy and fairness'''\n",
        "\n",
        "policies_path = f'{project_dir}/data/policies.txt'\n",
        "print(\"\\nWriting policies.txt...\")\n",
        "with open(policies_path, 'w') as f:\n",
        "    f.write(policies)\n",
        "\n",
        "# Write the corrected main.py file\n",
        "main_py_content = '''import json\n",
        "from typing import List, Dict, Any\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Force CPU usage and disable CUDA\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "torch.set_num_threads(4)\n",
        "torch.set_num_interop_threads(4)\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.backends.cuda.enable_mem_eager_sdp = False\n",
        "\n",
        "# Create FastAPI app first\n",
        "app = FastAPI()\n",
        "\n",
        "# Enable CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Initialize global variables\n",
        "model = None\n",
        "tokenizer = None\n",
        "flan_model = None\n",
        "vector_store = None\n",
        "articles = []\n",
        "policies = []\n",
        "policy_sections = []\n",
        "\n",
        "def split_policies(text: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Split policy text into sections based on headers.\"\"\"\n",
        "    try:\n",
        "        sections = []\n",
        "        current_section = {\"title\": \"\", \"content\": \"\"}\n",
        "\n",
        "        # Split text into lines and process\n",
        "        lines = text.split(\"\\\\n\")\n",
        "        for line in lines:\n",
        "            # Check if line is a header (all caps or starts with number)\n",
        "            if line.isupper() or re.match(r\"^\\\\d+\\\\.\", line):\n",
        "                # Save previous section if it exists\n",
        "                if current_section[\"title\"]:\n",
        "                    sections.append(current_section)\n",
        "                # Start new section\n",
        "                current_section = {\"title\": line, \"content\": \"\"}\n",
        "            else:\n",
        "                # Add line to current section\n",
        "                if current_section[\"content\"]:\n",
        "                    current_section[\"content\"] += \"\\\\n\"\n",
        "                current_section[\"content\"] += line\n",
        "\n",
        "        # Add the last section\n",
        "        if current_section[\"title\"]:\n",
        "            sections.append(current_section)\n",
        "\n",
        "        return sections\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in split_policies: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def initialize_components():\n",
        "    \"\"\"Initialize all required components for the API.\"\"\"\n",
        "    global model, tokenizer, flan_model, vector_store, articles, policies, policy_sections\n",
        "\n",
        "    try:\n",
        "        # Load SentenceTransformer model\n",
        "        logger.info(\"Loading SentenceTransformer model...\")\n",
        "        model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
        "        logger.info(\"SentenceTransformer model loaded\")\n",
        "\n",
        "        # Load Flan-T5 model and tokenizer\n",
        "        logger.info(\"Loading Flan-T5 model and tokenizer...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", local_files_only=True)\n",
        "        flan_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", local_files_only=True)\n",
        "        flan_model = flan_model.to(\"cpu\")  # Force CPU usage\n",
        "        logger.info(\"Flan-T5 model and tokenizer loaded\")\n",
        "\n",
        "        # Load data\n",
        "        logger.info(\"Loading data...\")\n",
        "        data_dir = Path(\"data\")\n",
        "\n",
        "        # Load articles\n",
        "        logger.info(\"Loading articles...\")\n",
        "        with open(data_dir / \"articles.json\", \"r\") as f:\n",
        "            articles = json.load(f)\n",
        "        logger.info(f\"Successfully loaded {len(articles)} articles\")\n",
        "\n",
        "        # Load and split policies\n",
        "        logger.info(\"Loading policies...\")\n",
        "        with open(data_dir / \"policies.txt\", \"r\") as f:\n",
        "            policies = f.read()\n",
        "        policy_sections = split_policies(policies)\n",
        "        logger.info(f\"Split policies into {len(policy_sections)} sections\")\n",
        "\n",
        "        # Create vector store\n",
        "        logger.info(\"Creating vector store...\")\n",
        "        texts = []\n",
        "        sources = []\n",
        "\n",
        "        # Add articles\n",
        "        for article in articles:\n",
        "            texts.append(article[\"body\"])\n",
        "            sources.append({\n",
        "                \"type\": \"article\",\n",
        "                \"title\": article[\"content_headline\"]\n",
        "            })\n",
        "\n",
        "        # Add policy sections\n",
        "        for section in policy_sections:\n",
        "            texts.append(section[\"content\"])\n",
        "            sources.append({\n",
        "                \"type\": \"policy\",\n",
        "                \"title\": section[\"title\"]\n",
        "            })\n",
        "\n",
        "        embeddings = model.encode(texts)\n",
        "        logger.info(f\"Created embeddings of shape: {embeddings.shape}\")\n",
        "\n",
        "        # Initialize FAISS index\n",
        "        dimension = embeddings.shape[1]\n",
        "        vector_store = faiss.IndexFlatL2(dimension)\n",
        "        vector_store.add(embeddings.astype(\"float32\"))\n",
        "        logger.info(\"Vector store created\")\n",
        "\n",
        "        # Store sources and texts for later use\n",
        "        app.state.sources = sources\n",
        "        app.state.texts = texts\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error initializing components: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question: str\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"status\": \"ok\", \"message\": \"CBC Editorial Assistant API is running\"}\n",
        "\n",
        "@app.post(\"/api/qa\")\n",
        "async def answer_policy_question(question: Question):\n",
        "    global model, tokenizer, flan_model, vector_store\n",
        "\n",
        "    if model is None or vector_store is None:\n",
        "        success = initialize_components()\n",
        "        if not success:\n",
        "            raise HTTPException(status_code=500, detail=\"Failed to initialize components\")\n",
        "\n",
        "    try:\n",
        "        # Encode question\n",
        "        question_embedding = model.encode([question.question])\n",
        "\n",
        "        # Search for similar content\n",
        "        D, I = vector_store.search(question_embedding.astype(\"float32\"), k=5)\n",
        "\n",
        "        # Get relevant text\n",
        "        citations = []\n",
        "        seen_texts = set()\n",
        "        seen_sources = set()\n",
        "\n",
        "        for idx in I[0]:\n",
        "            source = app.state.sources[idx]\n",
        "            text = app.state.texts[idx]\n",
        "\n",
        "            # Skip if we've already seen this text or source\n",
        "            if text in seen_texts or source[\"title\"] in seen_sources:\n",
        "                continue\n",
        "            seen_texts.add(text)\n",
        "            seen_sources.add(source[\"title\"])\n",
        "\n",
        "            # For articles, try to find the most relevant paragraph\n",
        "            if source[\"type\"] == \"article\":\n",
        "                paragraphs = text.split(\"\\\\n\\\\n\")\n",
        "                most_relevant_para = max(paragraphs, key=lambda p: model.encode([p])[0] @ question_embedding[0])\n",
        "\n",
        "                # Only add if the paragraph is relevant to the question\n",
        "                if model.encode([most_relevant_para])[0] @ question_embedding[0] > 0.3:\n",
        "                    citations.append({\n",
        "                        \"source\": f\"CBC Article: {source['title']}\",\n",
        "                        \"text\": most_relevant_para\n",
        "                    })\n",
        "            else:\n",
        "                # For policies, only add if the section is relevant to the question\n",
        "                if model.encode([text])[0] @ question_embedding[0] > 0.3:\n",
        "                    citations.append({\n",
        "                        \"source\": source[\"title\"],\n",
        "                        \"text\": text\n",
        "                    })\n",
        "\n",
        "        if not citations:\n",
        "            raise HTTPException(status_code=404, detail=\"No relevant information found\")\n",
        "\n",
        "        # Create prompt for Flan-T5\n",
        "        context = \"\\\\n\".join([f\"Source: {c['source']}\\\\nText: {c['text']}\" for c in citations])\n",
        "        prompt = f\"Context: {context}\\\\nQuestion: {question.question}\\\\nAnswer:\"\n",
        "\n",
        "        # Generate answer using Flan-T5\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "        outputs = flan_model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=200,\n",
        "            num_beams=4,\n",
        "            temperature=0.7,\n",
        "            no_repeat_ngram_size=2\n",
        "        )\n",
        "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Return the response\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"citations\": citations\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in QA endpoint: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    logger.info(\"Starting server...\")\n",
        "    success = initialize_components()\n",
        "    if success:\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "    else:\n",
        "        logger.error(\"Failed to initialize components. Server not started.\")\n",
        "        sys.exit(1)\n",
        "'''\n",
        "\n",
        "# Write the file\n",
        "with open('/content/drive/MyDrive/editorial_assistant/src/api/main.py', 'w') as f:\n",
        "    f.write(main_py_content)\n",
        "\n",
        "print(\"main.py has been updated successfully!\")\n",
        "\n",
        "# Create __init__.py files\n",
        "with open(f'{project_dir}/src/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "with open(f'{project_dir}/src/api/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "print(\"\\nCreated project structure in Google Drive:\")\n",
        "print(f\"Project directory: {project_dir}\")\n",
        "print(\"\\nVerifying directory structure:\")\n",
        "print(f\"Directory contents: {os.listdir(project_dir)}\")\n",
        "print(f\"src directory contents: {os.listdir(f'{project_dir}/src')}\")\n",
        "print(f\"src/api directory contents: {os.listdir(f'{project_dir}/src/api')}\")\n",
        "print(f\"data directory contents: {os.listdir(f'{project_dir}/data')}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Create a clean article\n",
        "article = {\n",
        "    \"content_id\": \"1.6272172\",\n",
        "    \"content_headline\": \"CBC N.L. launches annual Make the Season Kind campaign to support food banks\",\n",
        "    \"content_type\": \"Text\",\n",
        "    \"content_publish_time\": \"2021-12-06T04:30:00\",\n",
        "    \"content_last_update\": \"2021-12-06T04:30:00\",\n",
        "    \"content_edits\": \"0\",\n",
        "    \"content_categories\": [\n",
        "        {\"content_category\": \"Holidays\"},\n",
        "        {\"content_category\": \"Political campaigns\"},\n",
        "        {\"content_category\": \"Local food\"},\n",
        "        {\"content_category\": \"Food banks\"}\n",
        "    ],\n",
        "    \"content_tags\": [\n",
        "        {\"type\": \"generic\", \"name\": \"CBC Feed NL\"},\n",
        "        {\"type\": \"generic\", \"name\": \"CBC Feed NL Day\"},\n",
        "        {\"type\": \"generic\", \"name\": \"Food banks\"},\n",
        "        {\"type\": \"generic\", \"name\": \"Food donations\"},\n",
        "        {\"type\": \"generic\", \"name\": \"donations\"},\n",
        "        {\"type\": \"location\", \"name\": \"Newfoundland and Labrador\"},\n",
        "        {\"type\": \"organization\", \"name\": \"CBC\"},\n",
        "        {\"type\": \"organization\", \"name\": \"Salvation Army\"},\n",
        "        {\"type\": \"person\", \"name\": \"Rene Loveless\"}\n",
        "    ],\n",
        "    \"content_word_count\": \"288\",\n",
        "    \"content_department_path\": \"News/Canada/Nfld. & Labrador\",\n",
        "    \"body\": \"CBC N.L. is kicking off the annual Make the Season Kind campaign for the month of December with special programming and a virtual coming together in support of food banks across the province. This year, CBC N.L. is continuing to partner with the Community Food Sharing Association, an organization that distributes to food banks across Newfoundland and Labrador year-round to help keep pantries stocked for people in need. Included is the annual Feed N.L. Day on Dec. 10, which in 2020 helped raise $193,815 for local food banks. Some community organizations across Newfoundland and Labrador are experiencing increased calls for help leading up to the holidays. Bridges to Hope and Food First N.L. both say more first-time food bank users are reaching out. Maj. Rene Loveless of the Salvation Army said families and individuals are making tough decisions every day on how to put food on their tables while trying to make ends meet. \\\"When it comes to the increased cost of supplying food for their families, that's certainly a significant factor,\\\" he said. \\\"And it's a significant factor for us a provider as well. Our food dollar doesn't take us as far as it used to. So that's something that we're certainly seeing as well. Loveless said donations to his organization are going well so far this year. Last year, the Salvation Army helped 2,000 families over the holidays, he said, but added it's expected the need is going to increase by 15 per cent this time around. The annual Make the Season Kind campaign will be virtual again this year. The public can support the Community Food Sharing Association by making a donation online.\"\n",
        "}\n",
        "\n",
        "# Write to file\n",
        "articles_path = '/content/drive/MyDrive/editorial_assistant/data/articles.json'\n",
        "with open(articles_path, 'w') as f:\n",
        "    json.dump([article], f, indent=2)\n",
        "\n",
        "# Verify the file\n",
        "print(\"Verifying articles.json content:\")\n",
        "with open(articles_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(\"File content length:\", len(content))\n",
        "    print(\"First 100 characters:\", content[:100])\n",
        "    print(\"Last 100 characters:\", content[-100:])\n",
        "    # Try to parse the JSON to verify it's valid\n",
        "    json.loads(content)\n",
        "    print(\"JSON is valid!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qr5q1bfCSkU",
        "outputId": "a6ba4326-6466-4827-8a0b-7e6058c378a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying articles.json content:\n",
            "File content length: 3040\n",
            "First 100 characters: [\n",
            "  {\n",
            "    \"content_id\": \"1.6272172\",\n",
            "    \"content_headline\": \"CBC N.L. launches annual Make the Seas\n",
            "Last 100 characters: r. The public can support the Community Food Sharing Association by making a donation online.\"\n",
            "  }\n",
            "]\n",
            "JSON is valid!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install fastapi uvicorn sentence-transformers faiss-cpu transformers torch numpy pydantic requests python-multipart\n",
        "# Cell 2: Install required packages\n",
        "!pip install -q sentence-transformers transformers torch faiss-cpu fastapi uvicorn huggingface_hub[hf_xet]\n",
        "\n",
        "\n",
        "\n",
        "# Verify installations\n",
        "import fastapi\n",
        "import uvicorn\n",
        "import sentence_transformers\n",
        "import faiss\n",
        "import transformers\n",
        "import torch\n",
        "import numpy\n",
        "import pydantic\n",
        "import requests\n",
        "\n",
        "print(\"\\nDependencies installed successfully!\")\n",
        "print(f\"FastAPI version: {fastapi.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc1y5zKCWF6",
        "outputId": "3f478885-6845-482e-a6cd-356c7913f820"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "\n",
            "Dependencies installed successfully!\n",
            "FastAPI version: 0.115.12\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0bF63-ACZBT",
        "outputId": "79534cf3-8a28-4020-8ad0-eb37fc0f04fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Set environment variable for Colab\n",
        "import os\n",
        "os.environ[\"COLAB\"] = \"1\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vU88eyX8Cbjs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Start FastAPI server\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "\n",
        "print(\"Starting FastAPI server...\")\n",
        "print(\"Project directory:\", project_dir)\n",
        "\n",
        "# Print debug information\n",
        "print(\"\\nDebug Information:\")\n",
        "print(f\"Python path: {os.environ.get('PYTHONPATH', 'Not set')}\")\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Project directory contents: {os.listdir(project_dir)}\")\n",
        "print(f\"Data directory contents: {os.listdir(f'{project_dir}/data')}\")\n",
        "\n",
        "# Verify articles.json exists and is valid\n",
        "articles_path = f'{project_dir}/data/articles.json'\n",
        "print(\"\\nVerifying articles.json...\")\n",
        "if os.path.exists(articles_path):\n",
        "    try:\n",
        "        with open(articles_path, 'r') as f:\n",
        "            content = f.read()\n",
        "            print(f\"Articles file content length: {len(content)}\")\n",
        "            print(f\"First 100 characters: {content[:100]}\")\n",
        "            print(f\"Last 100 characters: {content[-100:]}\")\n",
        "            json.loads(content)  # Verify JSON is valid\n",
        "            print(\"Articles.json is valid\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading articles.json: {str(e)}\")\n",
        "else:\n",
        "    print(\"Error: articles.json not found!\")\n",
        "\n",
        "# Kill any existing process on port 8000\n",
        "print(\"\\nKilling any existing process on port 8000...\")\n",
        "os.system('fuser -k 8000/tcp')\n",
        "time.sleep(2)  # Wait for port to be freed\n",
        "\n",
        "# Start the server with logging\n",
        "print(\"\\nStarting server...\")\n",
        "log_file = f'{project_dir}/server.log'\n",
        "\n",
        "# Create a simple test script to verify the server\n",
        "test_script = f'''import uvicorn\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {{\"status\": \"ok\", \"message\": \"Test server is running\"}}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_script_path = f'{project_dir}/test_server.py'\n",
        "with open(test_script_path, 'w') as f:\n",
        "    f.write(test_script)\n",
        "\n",
        "# First try the test server\n",
        "print(\"\\nTesting with a simple server first...\")\n",
        "os.system(f'cd {project_dir} && python test_server.py > {log_file} 2>&1 &')\n",
        "time.sleep(5)\n",
        "\n",
        "# Check if test server is running\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "    print(f\"Test server response: {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        print(\"Test server is working!\")\n",
        "    else:\n",
        "        print(f\"Test server returned status {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"Test server error: {str(e)}\")\n",
        "\n",
        "# Kill the test server\n",
        "os.system('fuser -k 8000/tcp')\n",
        "time.sleep(2)\n",
        "\n",
        "# Now start the main server\n",
        "print(\"\\nStarting main server...\")\n",
        "server_cmd = f'cd {project_dir} && PYTHONPATH={project_dir} python src/api/main.py > {log_file} 2>&1'\n",
        "os.system(f'{server_cmd} &')\n",
        "\n",
        "# Wait for server to initialize\n",
        "print(\"\\nWaiting for server to initialize (30 seconds)...\")\n",
        "time.sleep(30)\n",
        "\n",
        "# Check if server is running and show logs\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Server started successfully!\")\n",
        "        print(\"You can now run the test cell.\")\n",
        "    else:\n",
        "        print(f\"Warning: Server returned status code {response.status_code}\")\n",
        "        print(\"\\nServer logs:\")\n",
        "        if os.path.exists(log_file):\n",
        "            with open(log_file, 'r') as f:\n",
        "                print(f.read())\n",
        "        else:\n",
        "            print(\"No log file found\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not verify server status - {str(e)}\")\n",
        "    print(\"\\nServer logs:\")\n",
        "    if os.path.exists(log_file):\n",
        "        with open(log_file, 'r') as f:\n",
        "            print(f.read())\n",
        "    else:\n",
        "        print(\"No log file found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOXD2iSgChbU",
        "outputId": "03a52013-7720-4897-b1e5-ef1c5945c863"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting FastAPI server...\n",
            "Project directory: /content/drive/MyDrive/editorial_assistant\n",
            "\n",
            "Debug Information:\n",
            "Python path: /env/python\n",
            "Current directory: /content/drive/MyDrive/editorial_assistant\n",
            "Project directory contents: ['data', 'src', 'test_server.py', 'editorial_assistant', 'server.log', 'run_server.py', 'requirements.txt']\n",
            "Data directory contents: ['.DS_Store', 'policies.txt', 'articles.json']\n",
            "\n",
            "Verifying articles.json...\n",
            "Articles file content length: 1982\n",
            "First 100 characters: [\n",
            "  {\n",
            "    \"content_id\": \"article1\",\n",
            "    \"content_headline\": \"CBC N.L. launches campaign to support f\n",
            "Last 100 characters:  content and the importance of protecting sources who share information through social media.\"\n",
            "  }\n",
            "]\n",
            "Articles.json is valid\n",
            "\n",
            "Killing any existing process on port 8000...\n",
            "\n",
            "Starting server...\n",
            "\n",
            "Testing with a simple server first...\n",
            "Test server response: 200\n",
            "Test server is working!\n",
            "\n",
            "Starting main server...\n",
            "\n",
            "Waiting for server to initialize (30 seconds)...\n",
            "Server started successfully!\n",
            "You can now run the test cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Test the API\n",
        "print(\"Starting API test...\")\n",
        "\n",
        "# Get the public URL from Colab\n",
        "from google.colab.output import eval_js\n",
        "public_url = eval_js(\"google.colab.kernel.proxyPort(8000)\")\n",
        "base_url = f\"http://localhost:8000\"  # Use localhost instead of public URL\n",
        "api_url = f\"{base_url}/api/qa\"\n",
        "\n",
        "print(f\"Testing API at: {api_url}\")\n",
        "\n",
        "# Test questions\n",
        "test_questions = [\n",
        "    \"What are the guidelines for using social media in news reporting?\",\n",
        "    \"How should anonymous sources be handled?\",\n",
        "    \"What are the requirements for writing headlines?\",\n",
        "    \"Tell me about the Make the Season Kind campaign\",\n",
        "    \"What are the guidelines for food bank donations?\"\n",
        "]\n",
        "\n",
        "def test_qa_endpoint(question):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Testing question: {question}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    try:\n",
        "        print(\"\\nSending question to QA endpoint...\")\n",
        "        print(f\"Request URL: {api_url}\")\n",
        "\n",
        "        response = requests.post(\n",
        "            api_url,\n",
        "            json={\"question\": question},\n",
        "            timeout=30\n",
        "        )\n",
        "\n",
        "        print(f\"Response status: {response.status_code}\")\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            print(\"\\nAPI Response:\")\n",
        "            print(\"\\nAnswer:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(result[\"answer\"])\n",
        "            print(\"\\nCitations:\")\n",
        "            print(\"-\" * 40)\n",
        "            for i, citation in enumerate(result[\"citations\"], 1):\n",
        "                print(f\"\\nCitation {i}:\")\n",
        "                print(f\"Source: {citation['source']}\")\n",
        "                print(f\"Text: {citation['text'][:200]}...\")\n",
        "        else:\n",
        "            print(f\"\\nError: Server returned status code {response.status_code}\")\n",
        "            print(\"Response:\", response.text)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError making request: {str(e)}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"\\nError decoding response: {str(e)}\")\n",
        "        print(\"Response:\", response.text)\n",
        "\n",
        "# First check if server is running\n",
        "print(\"\\nChecking if server is running...\")\n",
        "try:\n",
        "    response = requests.get(base_url, timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"Server is running!\")\n",
        "        print(\"\\nRunning test questions...\")\n",
        "\n",
        "        # Run all test questions\n",
        "        for question in test_questions:\n",
        "            test_qa_endpoint(question)\n",
        "            time.sleep(2)  # Small delay between questions\n",
        "\n",
        "    else:\n",
        "        print(f\"Server returned status {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to server: {str(e)}\")\n",
        "    print(\"\\nServer logs:\")\n",
        "    log_file = f'{project_dir}/server.log'\n",
        "    if os.path.exists(log_file):\n",
        "        with open(log_file, 'r') as f:\n",
        "            print(f.read())\n",
        "\n",
        "print(\"\\nTest completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9gjFTOd5Ckl0",
        "outputId": "0360741f-37bf-424c-bff1-96f1909807c8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting API test...\n",
            "Testing API at: http://localhost:8000/api/qa\n",
            "\n",
            "Checking if server is running...\n",
            "Server is running!\n",
            "\n",
            "Running test questions...\n",
            "\n",
            "================================================================================\n",
            "Testing question: What are the guidelines for using social media in news reporting?\n",
            "================================================================================\n",
            "\n",
            "Sending question to QA endpoint...\n",
            "Request URL: http://localhost:8000/api/qa\n",
            "Response status: 200\n",
            "\n",
            "API Response:\n",
            "\n",
            "Answer:\n",
            "----------------------------------------\n",
            "Journalists are required to verify information from social media sources before reporting, maintain professional boundaries, and clearly distinguish between personal and professional accounts\n",
            "\n",
            "Citations:\n",
            "----------------------------------------\n",
            "\n",
            "Citation 1:\n",
            "Source: 5. Follow CBC's style guide for capitalization and punctuation\n",
            "Text: CBC Editorial Guidelines: Social Media\n",
            "\n",
            "When creating content for social media:...\n",
            "\n",
            "Citation 2:\n",
            "Source: CBC Article: New guidelines for social media reporting\n",
            "Text: CBC has released updated guidelines for social media reporting. The new policy emphasizes accuracy, transparency, and responsible use of social media platforms. Journalists are required to verify info...\n",
            "\n",
            "Citation 3:\n",
            "Source: 3. The information cannot be obtained through on-the-record sources\n",
            "Text: When using anonymous sources:\n",
            "- Verify the information through multiple sources\n",
            "- Clearly explain to readers why anonymity was granted\n",
            "- Use descriptive terms (e.g., \"senior government official\" inste...\n",
            "\n",
            "================================================================================\n",
            "Testing question: How should anonymous sources be handled?\n",
            "================================================================================\n",
            "\n",
            "Sending question to QA endpoint...\n",
            "Request URL: http://localhost:8000/api/qa\n",
            "Response status: 200\n",
            "\n",
            "API Response:\n",
            "\n",
            "Answer:\n",
            "----------------------------------------\n",
            "Verify the information through multiple sources\n",
            "\n",
            "Citations:\n",
            "----------------------------------------\n",
            "\n",
            "Citation 1:\n",
            "Source: 3. The information cannot be obtained through on-the-record sources\n",
            "Text: When using anonymous sources:\n",
            "- Verify the information through multiple sources\n",
            "- Clearly explain to readers why anonymity was granted\n",
            "- Use descriptive terms (e.g., \"senior government official\" inste...\n",
            "\n",
            "Citation 2:\n",
            "Source: CBC Article: New guidelines for social media reporting\n",
            "Text: CBC has released updated guidelines for social media reporting. The new policy emphasizes accuracy, transparency, and responsible use of social media platforms. Journalists are required to verify info...\n",
            "\n",
            "================================================================================\n",
            "Testing question: What are the requirements for writing headlines?\n",
            "================================================================================\n",
            "\n",
            "Sending question to QA endpoint...\n",
            "Request URL: http://localhost:8000/api/qa\n",
            "Response status: 200\n",
            "\n",
            "API Response:\n",
            "\n",
            "Answer:\n",
            "----------------------------------------\n",
            "Source: 5. Follow CBC's style guide for capitalization and punctuation\n",
            "\n",
            "Citations:\n",
            "----------------------------------------\n",
            "\n",
            "Citation 1:\n",
            "Source: 3. The information cannot be obtained through on-the-record sources\n",
            "Text: When using anonymous sources:\n",
            "- Verify the information through multiple sources\n",
            "- Clearly explain to readers why anonymity was granted\n",
            "- Use descriptive terms (e.g., \"senior government official\" inste...\n",
            "\n",
            "Citation 2:\n",
            "Source: 5. Follow CBC's style guide for capitalization and punctuation\n",
            "Text: CBC Editorial Guidelines: Social Media\n",
            "\n",
            "When creating content for social media:...\n",
            "\n",
            "Citation 3:\n",
            "Source: CBC Article: New guidelines for social media reporting\n",
            "Text: CBC has released updated guidelines for social media reporting. The new policy emphasizes accuracy, transparency, and responsible use of social media platforms. Journalists are required to verify info...\n",
            "\n",
            "================================================================================\n",
            "Testing question: Tell me about the Make the Season Kind campaign\n",
            "================================================================================\n",
            "\n",
            "Sending question to QA endpoint...\n",
            "Request URL: http://localhost:8000/api/qa\n",
            "Response status: 200\n",
            "\n",
            "API Response:\n",
            "\n",
            "Answer:\n",
            "----------------------------------------\n",
            "The initiative, in partnership with the Community Food Sharing Association, aims to raise awareness and collect donations for food banks that are seeing increased demand.\n",
            "\n",
            "Citations:\n",
            "----------------------------------------\n",
            "\n",
            "Citation 1:\n",
            "Source: CBC Article: CBC N.L. launches campaign to support food banks\n",
            "Text: CBC N.L. has launched a campaign to support food banks across the province. The initiative, in partnership with the Community Food Sharing Association, aims to raise awareness and collect donations fo...\n",
            "\n",
            "================================================================================\n",
            "Testing question: What are the guidelines for food bank donations?\n",
            "================================================================================\n",
            "\n",
            "Sending question to QA endpoint...\n",
            "Request URL: http://localhost:8000/api/qa\n",
            "Response status: 200\n",
            "\n",
            "API Response:\n",
            "\n",
            "Answer:\n",
            "----------------------------------------\n",
            "aims to raise awareness and collect donations for food banks that are seeing increased demand\n",
            "\n",
            "Citations:\n",
            "----------------------------------------\n",
            "\n",
            "Citation 1:\n",
            "Source: CBC Article: CBC N.L. launches campaign to support food banks\n",
            "Text: CBC N.L. has launched a campaign to support food banks across the province. The initiative, in partnership with the Community Food Sharing Association, aims to raise awareness and collect donations fo...\n",
            "\n",
            "Test completed.\n"
          ]
        }
      ]
    }
  ]
}